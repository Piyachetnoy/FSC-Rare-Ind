??????????Few-shot?????????????????????*1?????*1Few-Shot Counting for Custom Industrial ObjectsPiyachet PONGSANTICHAI*1 and Fumitake Kato*1*1 Kato Laboratory Counting industrial objects remains challenging due to visual similarity, complex geometries, and environmental variability. Few-Shot Counting (FSC) reduces data requirements but cannot guarantee accuracy in all scenarios. We propose an adaptive Human-in-the-Loop (HITL) workflow in additional with confidence-based selective verification that routes uncertain predictions for human review. Our confidence score combines density map local variance and exemplar correlation, computed at peak locations identified via local maxima detection. Experiments on the INDT industrial dataset show that our approach achieves an MAE of 1.959 at 62% human intervention, outperforming random sampling at 75% intervention (MAE 2.950). This framework enables practical deployment with tunable trade-offs between accuracy and efficiency.Key Words: Few-Shot, Counting Automation, Industrial Applications, Data Visualisation, Human-in-the-Loop
1.?Introduction?Automated object counting is essential for inventory management and process optimization in industrial settings. Manufacturing facilities and warehouses routinely count structural components such as T-beams, L-beams, I-beams, and metal rods. These objects present significant identification challenges due to structural similarities and complex geometries. Conventional counting methods exhibit degraded performance under occlusions, shape variations, and cluttered arrangements typical of real-world environments.?Few-Shot Counting (FSC) addresses data scarcity by learning to count from minimal examples. FamNet (1) represents a notable approach in this domain, employing exemplar-based density map predictions that generalize to unseen object categories. However, FSC models cannot guarantee accurate predictions in all scenarios, particularly when images contain ambiguous regions, occlusions, or adverse lighting conditions.?This limitation motivates the present work. Rather than pursuing fully automated solutions, we propose a practical deployment strategy that leverages model efficiency while incorporating human judgment for uncertain cases. Our adaptive Human-in-the-Loop (HITL) workflow employs a confidence scoring mechanism to identify uncertain predictions, routing them for human verification while automatically accepting high-confidence predictions.?Our contributions include a confidence-based selective verification system that combines density map variance and exemplar correlation scores, experimental validation demonstrating that adaptive HITL outperforms random sampling strategies, and the INDT dataset comprising 576 images of industrial objects, along with practical deployment guidelines. Our code and dataset are available at https://github.com/Piyachetnoy/FSC-Rare-Ind.2.?Related Works?2?1? Few-Shot Counting with FamNet??has emerged as a solution for object counting with limited labeled data. Earlier work by Aich and Stavness (2) demonstrated that density-based counting with heatmap regulation can improve accuracy in complex scenes. Ranjan et al. (1) introduced FamNet, which learns to count objects using exemplar-based density map predictions with gradient-based test-time adaptation. Parnami and Lee (3) provided a comprehensive analysis of few-shot learning approaches, emphasizing metric-based learning and optimization strategies.?2?2? Human-in-the-Loop Systems??combine AI efficiency with human judgment for applications requiring high reliability (4). The core challenge lies in determining when human intervention is necessary, as illustrated in Fig. 1. Excessive intervention negates efficiency gains, while insufficient intervention compromises accuracy. Jakubik et al. (5) demonstrated effective HITL frameworks for object detection in floor plans, showing that selective human verification can significantly improve system reliability. Our work addresses this challenge through confidence-based selective verification, enabling adaptive intervention rates based on prediction uncertainty.Fig. 1  Human-in-the-Loop Flow Diagram3.?Methods?3?1? Few-Shot Counting with FamNet??is employed for density-based object counting. The architecture comprises a ResNet-50 feature extractor and a density prediction module. Given a query image and exemplar bounding boxes, the model extracts regional features from exemplars and correlates them with query image features to generate density maps. The predicted count is obtained by integrating over the density map, as illustrated in Fig. 2. We train FamNet models from scratch on our industrial datasets rather than fine-tuning from pre-trained weights, enabling the model to learn features specific to industrial object characteristics.Fig. 2  Deep Learning Model of Few-Shot Counting?3?2? INDT Dataset??is the dataset we constructed for industrial object counting, comprising images of T-beams, L-beams, I-beams, and square bars collected from public sources (Roboflow Universe: Centring Sheet, Angles, and Steel Beam datasets). INDT-576 (576 images, 4 categories, average 17.6 objects per image) and INDT-409 (409 images, 3 categories, average 8.2 objects per image) were created. Both datasets represent realistic industrial scenarios with varying lighting conditions, occlusions, and cluttered backgrounds.?Annotations were created using PBAT (Point and Box Annotation Tool), a custom tool we developed for efficient FSC-compatible annotation with point markers for counting targets and bounding boxes for exemplar regions.?3?3? Confidence Score and HITL Workflow??is a critical innovation in our approach, integrating a confidence-based, selective verification system. For each processed image, we compute a confidence score reflecting the model's certainty in its prediction. This score is derived from two primary indicators.?(1) Density Map Local Variance. The local variance is computed within regions surrounding each detected peak using image processing techniques (6). High variance indicates ambiguous or noisy predictions, suggesting lower confidence. Conversely, low variance with clear, isolated peaks indicates high confidence.?(2) Exemplar Correlation Score. We measure the correlation between the query image features and exemplar features in regions corresponding to detected objects. Higher correlation values indicate that detected objects closely match the exemplar characteristics, increasing confidence.C	? Confidence ScoreC_{var}	? Density Map Local VarianceC_{cor}	? Exemplar Correlation Score\alpha,\ \beta	? Weighting Coefficients (\alpha+\beta=1)?As in Equation (1), the overall confidence score C for an image is computed as a weighted combination.??C\ =\ \alpha\ á ,C-var. + ? á, C-cor.		(1)?Based on this confidence score, we implement an adaptive HITL workflow. With high confidence C>\theta, the model's prediction is accepted automatically without human verification. While Low confidence C\le\theta, the image and its predictions are flagged for human review, where the operator 
Table 3  Workflow comparison results (INDT-409 Test Set)
WorkflowMAERMSEHIR (%)Time (min)Fully Automated4.5306.5560%0.3Random Sampling (25%)3.8635.50825%10.3Random Sampling (50%)3.4945.05050%20.3Random Sampling (75%)2.9504.28775%30.3Adaptive HITL (( = 0.6)2.7324.39438%15.8Adaptive HITL (( = 0.7)1.9592.13062%25.3Adaptive HITL (( = 0.8)1.9652.04777%31.3Full Manual2.0002.000100%40.8
can correct the count or validate the prediction. This selective intervention strategy balances between accuracy and efficiency. By adjusting the threshold (, operators can control the trade-off between human workload and system accuracy.4.?Experiments?4?1? Experimental Setup??is set to evaluate using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). For the HITL evaluation, we also measure the Human Intervention Rate (HIR) and the estimated processing time. Based on preliminary studies, we estimate 30 seconds per human-verified image, with an average human error of 2 counts per image, reflecting realistic counting difficulties due to occlusions and ambiguous object boundaries.?4?2? Domain Training Effectiveness??result shown in Table 2, compares models on the INDT-576 test set (115 images, average 17.6 objects per image). All models are evaluated on the same test set to ensure fair comparison. The FSC-147 pre-trained model serves as a baseline, while INDT-trained models use the same architecture trained from scratch on industrial data.Table 2  Model comparison on INDT-576 test setsModelINDT-576 Test SetMAERMSEFSC-147 pre-trained10.5615.72Trained with INDT-5769.50113.81Trained with INDT-4099.36416.99??Domain-specific training yields improvements over the pre-trained baseline. Both INDT-trained models reduce MAE by approximately 11% compared to the FSC-147 pre-trained model. The INDT-409-trained model achieves the lowest MAE (9.364) despite being trained on fewer images with different object categories, demonstrating effective transfer learning across industrial object types.?4?3?HITL Workflow Comparison??We compared four workflows on 81 test images using the INDT-409-trained model: Full Automated, all predictions accepted without verification; Full Manual, every prediction reviewed by a human; Random Sampling, a fixed percentage randomly selected for verification; Adaptive HITL, Confidence-based selective verification.Fig. 3  Accuracy-Efficiency Trade-off Curves?Fig. 3 shows MAE vs. Human Intervention Rate for different workflows. The adaptive HITL curve dominates random sampling at equivalent intervention rates, indicating better performance. The results demonstrate substantial advantages of the adaptive HITL we proposed. From Table 3, We can tell that our approach has three major strengths, which are,?(1) Comparable HIR: Adaptive HITL (=0.6 achieves MAE 2.732 at 38% HIR, significantly outperforming Random Sampling at 50% HIR (MAE 3.494)?(2) Comparable accuracy: Adaptive HITL (=0.7 achieves MAE 1.959 at 62% HIR, surpassing Random Sampling at 75% (MAE 2.950)?(3) Near-optimal accuracy: Adaptive HITL (=0.8 approximates Full Manual accuracy (MAE of approximately 2.0) while reducing human effort by 38%?The confidence-based approach focuses human effort on genuinely difficult cases, whereas random sampling allocates effort inefficiently across both trivial and challenging cases.Fig. 4  Deep Learning Model of Few-Shot Counting5.?Conclusion?This paper presents an approach to industrial object counting that combines Few-Shot Counting with an adaptive Human-in-the-Loop workflow. The proposed confidence-based selective verification achieves superior accuracy-efficiency trade-offs compared to random sampling, attaining an MAE of 1.959 at 62% human intervention, versus 2.950 at 75% for random sampling.?The principal finding is that complete automation is not necessary for practical deployment. By intelligently routing uncertain cases to human verification, the system achieves near-optimal accuracy while substantially reducing human workload. The tunable threshold parameter enables flexible deployment across scenarios with varying accuracy requirements.?Future work will investigate automatic threshold adaptation based on human feedback and extension to more diverse industrial object categories.ReferencesV. Ranjan, U. Sharma, T. Nguyen, and M. Hoai, "Learning to count everything", in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 3394-3403.S. Aich and I. Stavness, "Improving object counting with heatmap regulation", arXiv preprint arXiv:1803.05494, 2018.Fujioka, H., Introduction to Digital Image Processing, SHOKODO, Vol. 2, (2003).A. Parnami and M. Lee, "Learning from few examples: A summary of approaches to few-shot learning", arXiv preprint arXiv:2203.04291, 2022.E. Brynjolfsson and A. McAfee, The second machine age: Work, progress, and prosperity in a time of brilliant technologies, WW Norton & company, 2014.J. Jakubik, P. Hemmer, M. Všssing, B. Blumenstiel, A. Bartos, and K. Mohr, "Designing a human-in-the-loop system for object detection in floor plans", in Proceedings of the AAAI Conference on Artificial Intelligence, 2022, vol. 36, pp. 12524-12530.S. van der Walt et al., "scikit-image: image processing in Python", PeerJ, vol. 2, p. e453, 2014.